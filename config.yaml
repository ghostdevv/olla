# Olla Configuration
server:
  host: "0.0.0.0"
  port: 19841
  read_timeout: 30s
  write_timeout: 0s
  shutdown_timeout: 10s

proxy:
  connection_timeout: 30s
  response_timeout: 900s
  read_timeout: 300s
  max_retries: 3
  retry_backoff: 500ms
  load_balancer: "priority"

discovery:
  type: "static"  # static, consul, etcd
  refresh_interval: 30s
  static:
    endpoints:
      - url: "http://localhost:11434"
        priority: 100
        health_check_url: "http://localhost:11434/"
        check_interval: 5s
        check_timeout: 2s
      - url: "http://192.168.0.1:11434"
        priority: 200
        health_check_url: "http://192.168.0.1:11434/"
        check_interval: 5s
        check_timeout: 2s
  consul:
    address: "localhost:8500"
    service_name: "ollama"
  etcd:
    endpoints:
      - "localhost:2379"
    key_prefix: "/ollama/endpoints"

logging:
  level: "debug"  # debug, info, warn, error
  format: "json"  # json, text
  output: "stdout"  # stdout, file

telemetry:
  metrics:
    enabled: true
    address: ":9090"
  tracing:
    enabled: false
    endpoint: "localhost:4317"
    sample_rate: 0.1

security:
  tls:
    enabled: false
    cert_file: "cert.pem"
    key_file: "key.pem"
  mtls:
    enabled: false
    ca_file: "ca.pem"

plugins:
  directory: "./plugins"
  enabled:
    # - "priority_balancer"
  config:
    # priority_balancer:
    #   some_option: "value"